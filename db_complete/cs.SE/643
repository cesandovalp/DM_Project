program generat user intent deep neural network lili mou rui men zhang zhi jin softwar institut school eec peke univers beij china menruimr lige zhanglu zhijin abstract paper envis program generat sce nario recurr neural network rnns user express intent natur languag rnn automat generat correspond code charact charact fashion demonstr feasibl case studi empir analysi fulli techniqu practic point cross disciplinari challeng includ model user intent provid dataset improv model architectur long term address field program generat realiti futur decad ward practic categori subject descriptor artifici intellig automat program program synthesi general term algorithm keyword deep learn recurr network program generat introduct imagin scenario softwar engin exist abund high qualiti sourc code well comment document larg softwar repositori pow machin deep neural network learn map ping natur languag problem descript sourc code develop user express intent natur languag repositori learn machin automat output desir code solut permiss digit hard copi work person classroom grant fee provid copi distribut profit commerci advantag copi bear notic full citat copi republish post server redistribut list requir prior specif permiss fee copyright acm xxxxx compel featur process work manner requir man knowledg complet languag independ thing need repres sentenc program charact learn machin automat read natur languag sentenc charact charact captur user intent generat code fashion learn machin differ code retriev system generat code exist code flexibl vulner code correct satisfi syntax plement desir function code usabl post edit scenario automat program generat long dream softwar engin close varieti task algorithm discoveri program assist tradit approach typic weak term autom abstract exampl manna propos deduct approach flener induct approach method quir human design specif program generat genet program automat search space candid program ineffici care chosen mutat crossov oper pro vide natur languag program emerg decad pseudo compil natur languag low level abstract nowaday softwar artifact includ code docu mentat big data github sourc forg provid suffici train data code corr spond comment document princi ple train generat model program base natur languag natur languag process nlp communiti wit breakthrough amaz task includ question swere machin translat imag caption gen erat cross disciplinari advanc bring opportun automat program generat paper investig case studi feasibl generat execut function coher ent code recurr neural network rnns empir analysi reveal mechan rnns accomplish goal envis scenario tech niqu help real task address long term challeng conced remain long program genera tion practic realiti futur decad case studi model recurr network varieti machin learn method deep neural network deep learn cent groundbreak advanc featur abil learn ing high complic featur automat program generat prefer recur rent neural network rnns suitabl mod ele time seri data sequenc charact iter natur rnn typic den layer chang discret time step input data process delin figur theoret analysi recurr neural network equival ture machin train rnns earli year difficult gradient blowup vanish problem long short term memori lstm unit gate unit design balanc retain previous state memor current time step make rnns easier train basi sutskev design rnn model sequenc sequenc generat idea read input sequenc end special symbol sequenc depict figur output rnn appli softmax layer time step predict probabl occur current step symbol highest probabl chosen fed network input time step process iter special symbol generat network figur rnn architectur appli sequenc dif ferent granular word level word level charact level rnn generat model expect achiev remark amaz formanc success applic includ generat text music linux code empir studi rnns good model syntax aspect parenthesi pair indent work push automata capa ble captur semant linux code generat exampl plausibl compil lack coher function curious rnns generat exe cutabl function coher sourc code essenc benefit real softwar engin task accomplish goal leverag dataset ped agog program onlin judg system intend undergradu cours introduct comput system compris program problem student submit sourc code specif problem system judg valid automat ning notic program correspond specif problem exact function dataset suitabl trial train neural network generat function coher program fed network program problem sourc code sam ples preprocess program preced symbol refer word charact granular applic output softmax hidden layer lstm unit input oneÂ­hot input sequenc output sequenc figur sequenc sequenc recurr neural network adapt input sequenc output sequenc comment find maximum second maxi mum number serv input sequenc figur program solv prob lem serv output sequenc figur figur illustr train sampl afor mention program problem result analysi figur sampl code generat rnn quick analysi find code execut post correct charact program compil function correct answer fundament question rnn generat code simpli memor train sampl case rnn work copi past fashion degrad problem trivial case examin train data observ exist program train set rule possibl rnn work exact memoriz ing detect code train set figur interest provid expla nation aspect program structur figur code structur generat code implement algorithm scan array find max imum second maximum number tice structur abstract syntax tree exact differ variabl definit interest detail rnn recogn equival loop follow exact sampl code train set remain correct variabl train sampl variabl figur gener ate code array cach want number structur diverg network awar variabl generat remain herent program entir dataset configur web site http site rnngenprogram figur code generat rnn code correct wrong charact charact total high light figur code structur train set detect ccfinder code identifi train set detect ccfinder note preserv indent space feed error identifi max return type void style find train sampl code style term indent feed sens train program written junior programm follow standard style convent network idea style train sampl correct program network difficulti learn syntax program generat code compil analysi gain basic idea rnn generat program rnn recog nize comment find maximum second maximum number preced code input point experi rnn understand mean sentenc read comment rnn switch hidden state generat code function function rnn awar aspect program includ structur gen erat choos charact condit previous charact condit input rnn abil mix structur remain coher prospect roadmap simpl preliminari case studi anal ysis provid illumin pictur program generat deep neural network point sev eral scenario deep learn benefit real practic topic long term studi understand changeabl user intent current case studi abil recogn intent generat correspond code practic oftentim face changeabl requir user address problem direct extens train parametr code gener ator argument file name protocol plicit express natur languag tackl challeng prospect train network generat primit code snip pet glue instanc network learn write code find maximum number find minimum number generat snippet subsequ read instruct find maximum minimum number incorpor multipl sourc user intent develop softwar programm find code depend context defin variabl exist api call sequenc addit function scenario train network fill miss block code admit code complet general sens problem real istic task specif scenario exampl typic read txt file java involv cre ate fileread bufferedread read line file close file catch except standard pipelin generat automat ical neural network provid context code despit promis futur rnns generat sourc code effort multipl disciplin includ nlp machin learn communiti question communiti defin intent provid dataset train function generat argument function collect dataset larg inform train clean includ nois open question nlp machin learn communiti hand continu improv neural architectur attent base network exampl propos mitig problem long input sequenc compos fix size vector studi need term understand memori capac rnns generat data coher semant revis generat data conced rnns generat program differ write program human appear unrealist current train learn machin includ ing deep neural network fulli understand natur languag program languag support exist evid literatur case studi paper deem program generat futur work deep learn program analysi year wit birth program anal ysis base deep neural network previous work learn program vector represent serv pre train phrase deep learn propos tree base convolut neural network classifi program function detect sourc code pattern zaremba rnns estim output strict python program allamani leverag vec tor represent method name model discrimin task view classif problem karpathi train rnn base languag model code maxim joint probabl program differ ent studi paper investig neural model synthes execut function coher ent program demand match user intent captur intern structur sourc code conclus remark paper train recurr neural network rnn generat execut function coher sourc code initi work demonstr possibl automat program generat analyz ing mechan envis scenario techniqu appli softwar engin ing task futur decad call studi multipl disciplin address direct refer allamani barr bird sutton suggest accur method class name esec fse cho van merri nboer bahdanau bengio properti neural machin translat encod decod approach arxiv preprint chorowski bahdanau serdyuk cho bengio attent base model speech recognit arxiv preprint cozzi king macho write program natur languag exampl technic report univers illinoi urbana champaign flener partridg induct program autom softw engin gulwani dimens program synthesi proc acm sigplan symposium principl practic declar program helmuth spector general program synthesi benchmark suit proc genet evol comput conf acm hochreit schmidhub long short term memori neural comput hyo tyniemi ture machin recurr neural network proc step karpathi unreason effect recurr neural network http rnn effect karpathi johnson visual understand recurr network arxiv preprint kno mezini pegasus step naturalist program languag oopsla kumar irsoy dynam memori network natur languag process arxiv preprint lecun bengio hinton deep learn natur manna walding deduct approach program synthesi acm tran program languag syst mou jin zhang wang tbcnn tree base convolut neural network program languag process aaai workshop mou liu peng jin zhang build program vector represent deep learn arxiv preprint pascanu mikolov bengio difficulti train recurr neural network arxiv preprint sutskev vinyal sequenc sequenc learn neural network nip weimer nguyen goue forrest automat find patch genet program ics attend neural imag caption generat visual attent arxiv preprint zaremba sutskev learn execut arxiv preprint 