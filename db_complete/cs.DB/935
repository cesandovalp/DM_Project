evalu rdf distribut algorithm implement apach spark olivi cure hubert naack moham amin baazizi bernd amann sorbonn universit upmc univ pari umr pari cnrs umr pari franc abstract queri larg rdf data set effici manner quir sophist distribut strategi innov solut propos optim data distribut prede fine queri workload paper present depth analysi periment comparison repres complementari distri bution approach achiev fair experiment apach spark common parallel comput framework rewrit concern algorithm spark api spark guaran tee term fault toler high avail scalabl essenti system implement aim highlight fundament implement independ characterist proach term data prepar load balanc data replic extent queri answer cost perform present measur test system synthet real data set queri workload differ characterist partit constraint introduct year number paper publish distribut issu rdf databas system main motiv movement effici manag grow size produc rdf data set repositori hundr million billion rdf tripl frequent popular data model big data ecosystem rdf cope issu scalabl high avail fault toler system address issu nosql system general adopt scale approach consist distribut data storag process cluster commod hardwar depend data model well optim distribut term data replic rate load balanc queri answer formanc hard achiev distribut approach set data transform process step intens concern graph general obtain balanc partit hard problem system propos heurist base approach tend produc distribut interest properti queri process context suprem properti abil limit amount data exchang network constitut cluster fact distribut join process machin transfer larg local comput temporari result machin process situat total durat queri answer process domin exchang larg data chunk hundr thousand gigabyt uncommon cluster network system consid distribut storag queri answer rdf data appear earli histori rdf system edutella rdfpeer tackl partit issu earli system virtuoso base hash rdf tripl compon frequent subject henceforth denot nhopdb attempt graph parti tion approach fragment rdf dataset system reinvigor communiti topic system extend graph partit approach warp complain limit shape consequ plethora distribut strategi easi identifi effici solut context object paper clarifi situat conduct evalu lead rdf tripl distribut algorithm second goal consid apach spark parallel comput framework host implement relev context larg portion exist rdf dis tribut databas nhopdb semstor shape shard implement apach hadoop open sourc mapreduc refer implement limit consid mapreduc databas system identifi high rate disk read write spark precis effici time hadoop work data store main memori experiment conduct reimplement approach hash base base graph partit hybrid sys tem evalu dataset synthet real vari cluster set total queri differ term shape star properti chain select analyz experi mentat conduct term time requir prepar data load balanc data replic rate queri answer perform background knowledg rdf sparql rdf schema free data model permit describ data web consid cornerston semant web web data assum disjoint infinit set rdf uri refer blank node liter tripl call rdf tripl subject predic object assum infinit set variabl disjoint recurs defin tripl pattern tripl sparql tripl pattern tripl pattern repres group tripl pattern match option set pattern extend solut induc union denot pattern altern tripl pattern iii tripl pattern built condit express filter tripl pattern enabl restrict solut tripl pattern match express sparql syntax select approach sql queri select claus specifi variabl appear queri result set apach spark apach spark cluster comput framework design impl mentat start amplab apach hadoop spark enabl parallel comput unreli machin automat handl local awar schedul fault toler load balanc task system base data flow comput model spark effici hadoop applic requir reus work dataset multipl par allel oper effici resili distribut dataset rdd distribut lineag support fault toler memori abstract enabl perform memori comput hadoop disk base spark api simplifi program task integr function nativ support hadoop join filter meti graph partition complex partit graph optim manner method defin propos approxim algo rithm general effici larg graph multi level propag approach frequent graph coarsen size permit approxim solut uncoarsen meti system approach reach limit graph half billion tripl meti take input unlabel undirect graph integ correspond desir number partit output partit number node graph nhopdb warp system meti partit rdf graph http org rdf sparql queri system distribut algorithm main featur design principl distri bution method select consid approach character hash graph partit base categori compos approach system describ confer public system correspond hybrid approach mix hash base approach replic strategi enabl effici process long chain queri note consid system partit rang base approach rare encount exist system ineffici hash base approach approach defin correspond famili rdf databas system specif system extend manner system replic tripl partit random hash distribut random hash base solut key data partit correspond data store data model instanc key correspond intern tripl identifi oper entir tripl solut adopt system approach requir addit data structur identifi partit entri store element requir direct lookup hash function method key form random partit exist requir addit structur direct lookup cluster node tripl locat round robin approach consid approach work guarante nice queri process properti queri shape star properti chain tree cycl hybrid rdf tripl element hash system key provid hash function element rdf tripl frequent approach partit tripl subject object predic element consid partit subject nice properti ensur star shape queri queri compos graph node degre greater perform local machin provid guarante queri compos properti chain complex queri pattern advantag approach requir addit structur locat partit key system virtuoso jena clusteredtdb shard adopt approach graph partit base approach hash base approach present requir high data chang rate network complex queri pattern corr spond star address issu organ replic data analyz queri workload cours organ process cost consid attent system correspond approach consid nhopdb distribut approach present compos step stage rdf dataset transform meti graph partition remov properti undirect graph subject object encod contigu translat tripl alloc cluster partit state stage denot hop second stage start correspond overlap strategi perform call hop guarante intuit partit leaf extend tripl subject correspond second stage perform time suc cessiv generat partit execut increas hop guarante singl unit describ architectur compos data partition set worker correspond rdf databas instanc queri execut local singl node enjoy optim machineri rdf queri answer set span multipl partit hadoop mapreduc system supervis queri process warp warp system influenc nhopdb partout system author warp work partout borrow graph partit approach hop guarante partout refin tripl alloc consid queri workload set frequent perform queri dataset system consid queri workload provid fact queri transform set queri pattern result warp guarante frequent queri process local exchang data machin queri partit suffici data result queri union local warp proceed comput data partit meti graph partition fragment data partit subject load data partit independ rdf manag system replic strategi appli ensur hop guarante queri pattern warp comput number tripl repli cate decompos pattern set local queri evalu local queri candid start point call seed queri evalu entir queri pattern main idea warp bring miss tripl par tition tripl seed candid partit comput cost transfer miss tripl current partit cours select seed queri candid minim cost warp system implement distribut join oper combin local queri local queri execut rdf machineri hybrid approach design origin hybrid approach motiv analysi warp system well hash base solut highlight confirm hash base solut requir short data prepar time poor queri answer formanc complex queri pattern hand warp system propos interest analysi queri workload translat effici data distribut will data prepar warp spent graph partit stage interest combin hash base partit queri workload awar refin spark system implement dataset load encod dataset load hadoop file system hdfs experiment provid measur load stage stress load rate cluster averag tripl second rdf store dataset encod provid distinct int ger node edg graph chapter present rdf tripl encod method comput complet perform parallel step spark framework provid implementa tion detail space limit encod dataset dictionari properti subject object load hdfs experiment data load spark program hdfs hash base approach approach straightforward context spark pro vide api method partit dataset case random hash partit system comput partit tripl consult http wiki implement detail subject predic object key tripl tripl ele ment hash subject key partit method implement extend provid form replic queri answer evalu perform forthright translat sparql spark script requir mix map filter join distinct method perform rdds graph partit base approach system partit categori requir three meti step prepar comput transform meti deal unlabel undirect graph start remov predic dataset append revers subject object pair pair set yield undirect graph meti impos limit term cept graph size largest graph process half billion node consequ limit experiment dataset rdf tripl provid undirect transform yield graph node output meti set map asser tion node partit base map alloc tripl partit subject term data encod extend tripl partit identifi yield quad note stage partit identifi consid logic physic data store machin stress prepar transform phase describ perform parallel spark program concern nhopdb system hop guarante comput rdd correspond generat quad spark program execut time hop guarante intuit warp implement analyz queri workload general izat spark built oper instanc consid basic graph pattern henceforth bgp queri denot advisor worksfor suborganis system filter oper select tripl match advisor worksfor suborgan properti join oper perform join equal predi cate variabl queri result set bind extend notion variabl bind partit identifi tripl instanc extract result unencod read form repres bob alic alic dbteam dbteam extract result tripl bind worksfor alic dbteam alic dbteam bound vari abl locat partit tripl partit effici access count number tripl replic instanc consid seed advisor replic tripl alic worksfor dbteam partit copi partit earlier consid candid seed choos seed impli minim number tripl replic step extend partit replic straight forward union oper final queri purpos queri extend predic forc local evalu join tripl partit identifi hybrid approach approach mix subject base hash method warp workload awar process standard represent tripl quad abil easili handl data transform code effort experi low experiment set dataset queri evalu synthet real dataset synthet data set correspond well establish lubm three instanc lubm denot parameter univers real data set consist wikidata free collabor knowledg base will replac freebas tabl present number tripl well size data set data set tripl file size lubm lubm lubm wikidata tabl dataset statist run exampl concern queri select three sparql queri lubm queri denot creat addit denot requir hop guarante perform local nhopdb warp hybrid implement complement queri evalu creat queri wikidata experi resp take form hop properti chain queri select lubm second shape simpl star motiv absenc form queri set queri present appendix comput environ evalu deploy cluster consist dell poweredg run debian distribut kernel version machin ram intel xeon processor equip core run allow thread parallel hyperthread number virtual core amount core machin term storag machin equip sata disk machin connect ethernet network adapt spark version implement experi scala version spark set requir total number core cluster experi consid cluster machin set number core core experiment queri workload wikidata conduct experiment warp hybrid approach dataset meti limit dataset half edg handl nhopdb warp fact hybrid system reli subject hash meti conduct experiment system data prepar figur present data prepar process time sys tem expect hash base approach effici graph partit base approach time faster pend number partit fact meti run singl machin test parmeti parallel version meti hash oper perform parallel spark cluster evalu emphas hybrid approach present interest compromis distribut method famili evaluat ing process step solut find hash base approach process time spent load dataset remain time spent partit data graph partit approach correspond time spent meti creat partit durat increas larger dataset size explain time spent graph partit approach increas machin appli solut machin lead reduct prepar process time fig data prepar time balanc storag load balanc aspect distribut data storag queri purpos figur standard deviat log scale system graph partit base hybrid approach consid standard deviat partit size partit process meti partit hop guarante applic hash base approach hybrid approach best solu tion close obvious hash partit ing approach concentr load balanc graph partition reduc number edg cut fragment process hybrid approach well balanc applic warp queri workload awar strategi random base hash viation subject hash high degre node increas size partit rang standard deviat val nhopdb approach effici graph partit solut high number queri consid queri workload consid analysi conduct real dataset queri workload confirm interest conclus fig standard deviat data replic intrins solut node replic node object partit subject correspond hop guarante ensur valid data interest tripl replic nhopdb warp hybrid solut replic tabl replic rate system lubm dataset conclus drawn tabl meti base approach effici subject hash hybrid system rememb minim edg cut graph partition group node close input graph second par tition cluster replic obtain hop guarante replic queri workload awar method warp nalli stress replic hybrid approach consid accept data replic durat highlight queri process order effici process local queri fair support perform comparison distribut set comput resourc local distribut run local queri run parallel machin scheme nhopdb warp hybrid data set lubm lubm tabl replic rate comparison three partit scheme three cluster size access partit exploit multicor machin perform experi interest consid inter partit parallel intra partit parallel well intra partit parallel fulli support spark partit unit data core process core machin split partit partit spark allow partit resid machin expect futur version spark will allow control absenc tripl replic hash base solut impact limit case system replic instanc queri workload awar solut warp hybrid conduct experi workaround forc spark machin partit local queri spark slave machin load data partit process queri local parallel core fair account possibl local queri faster partit partit repeat experi partit report maximum respons time case nhopdb involv requir develop special dedi cate queri processor special spark fulli benefit data frag mentat nutshel system combin intra inter partit queri processor queri subgraph local second perform join partit triev temporari topic paper concern evalu distribut strategi detail implement queri processor work nhopdb system tabl present queri process time dataset space limit execut time partit experi web site companion highlight parti tion effici queri process tabl clear highlight warp system effici hash base solut viousli simpler queri local requir inter partit communic spark version conduct experi measur inter node format communic fact shuffl read measur indic total exchang local node global network fig queri evalu partit work interest work publish distribut rdf data system semstor shape origin posit common queri workload semstor divid plete rdf graph set path cover origin graph node node overlap path path denot root graph rsg short generat start node null degre root leav special workaround handl cycl occur root posit cycl reachabl root idea regroup rsg differ ent partit hard problem author propos approxim solut solut cluster approach regroup rsg common segment partit limit approach high dimension vector handl algorithm size vector correspond number node graph second limit lack effici balanc number tripl partit fact system oper coars grain level rsg balanc level semstor final limit term join pattern effici handl subject object subject subject join pattern pattern object object requir inter node communic motiv shape system graph partit approach scale hybrid solut propos replac graph partit step hash partit nhopdb system replic hop guarante consid queri workload risk inter partit communic long chain queri longer hop guarante conclus perspect paper present evalu distribut system rang portant partit categori hash graph partit choic spark framework motiv high perform erat consid time faster hadoop mapreduc system design top hadoop awar rdf data manag system run top spark main motiv experi exist partit solut scale grace billion tripl instanc meti partition limit half billion tripl semstor work reli cluster vector dimens amount number node data process million case comput distanc high dimens current spark spars vector appli dimens reduct algorithm vector tractabl conclus experi basic hash base partit solu tion viabl distribut rdf manag prepar cost requir load tripl machin fulli support under spark system emphas experimenta tion spark scale billion tripl simpli extra machin replic system hinder avail reduc parallel queri process involv lot network communic complex queri requir retriev data partit make intens main memori spark high potenti system clear measur evalu stress fast access larg rdf dataset extent readi sacrific perform process complex queri pattern hash base solut spark good compromis concern nhopdb warp approach consid meti drawback base observ investig hybrid candid solut involv heavi prepar step retain interest queri workload awar replic strategi approach interest data warehous common queri materi view well identifi hybrid solut best world experi clear emphas replic overhead compar pure warp approach margin gain data prepar concern spark highlight process distribut rdf queri effici system step data prepar queri process homogen rewrit sparql queri scala languag support spark easi consid room optim version spark suppos provid feedback data exchang network help fine tune experi design complet product readi system refer http sim baazizi bollack evan paritosh sturg taylor freebas collabo rativ creat graph databas structur human knowledg proceed acm sigmod intern confer manag data sigmod york usa acm cai frank rdfpeer scalabl distribut rdf repositori base structur peer peer network proc intern wide web confer york citi usa cure blin rdf databas system edit morgan kaufmann nov dean ghemawat mapreduc simplifi data process larg cluster osdi erl virtuoso hybrid rdbms graph column store ieee data eng bull fiduccia mattheys linear time heurist improv net work partit proceed design autom confer dac las vega nevada usa june galarraga hose schenkel partout distribut engin effici rdf process corr guo pan heflin lubm benchmark owl knowledg base system web sem gurajada seufert miliaraki theobald triad distribut share rdf engin base asynchron messag pass intern confer manag data sigmod usa june hammoud rabbou nouri beheshti sakr dream dis tribut rdf engin adapt queri planner minim communic pvldb harth umbrich hogan decker feder repositori queri graph structur data web semant web ternat semant web confer iswc aswc busan korea novemb hose schenkel warp workload awar replic partit rdf workshop proceed ieee intern confer data engin icd huang abadi ren scalabl sparql queri larg rdf graph pvldb karypi kumar fast high qualiti multilevel scheme parti tion irregular graph siam sci comput dec lee liu scale queri big rdf graph semant hash partit pvldb nejdl wolf decker sintek naev nilsson palm risch edutella network infrastructur base rdf proceed eleventh intern wide web confer usa neumann weikum rdf engin scalabl manag rdf data vldb rohloff schantz high perform massiv scalabl distribut system mapreduc softwar framework shard tripl store pro gram support innov emerg distribut applic psi eta york usa acm sadalag fowler nosql distil guid emerg polyglot persist addison wesley profession edit stonebrak abadi dewitt madden paulson pavlo rasin mapreduc parallel dbmss friend foe commun acm vrandec kro tzsch wikidata free collabor knowledgebas commun acm zhou yuan jin liu semstor semant preserv distribut rdf tripl store proceed acm intern confer enc confer knowledg manag cikm york usa acm zaharia chowdhuri das dave mccauli franklin shenker stoica resili distribut dataset fault toler abstrac tion memori cluster comput proceed usenix sympo sium network system design implement nsdi san jose usa april zaharia chowdhuri franklin shenker stoica spark cluster comput work set usenix workshop hot topic cloud comput hotcloud boston usa june zeng yang wang shao wang distribut graph engin web scale rdf data pvldb queri queri evalu select select select select http select select 